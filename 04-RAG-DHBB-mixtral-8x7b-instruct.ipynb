{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb125839-bee8-4ecf-b296-d3e69829d0c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install -U --quiet databricks-sdk==0.40.0 databricks-agents==0.16.0 databricks-langchain==0.3.0 mlflow[databricks]==2.20.2 databricks-vectorsearch==0.49 langchain==0.3.19 langchain_core==0.3.37 bs4==0.0.2 markdownify==0.14.1 grpcio-status==1.59.3 # Temporary pin: grpcio version to avoid protobuf conflict.\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48e0a6a5-2462-440f-8c61-a054c5ba1ce1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Percebi um viés com o llama-3-1-70d.\n",
    "Caso da Marta Suplicy,\n",
    "Onde a associação com o tema de sexualidade funciona muito bem, mas em relação à máfia do transporte, que está no verbete, ele ignora.\n",
    "\n",
    "Vou montar outro chat com o mixtral para comparar.\n",
    "\n",
    "Vou reutilizar o mapa de vetores conforme criado em em \"RAG-DHBB-llama-3-1-70b-instruct\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51cceadb-b32d-47d7-9a2f-942d7d739621",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Deploy our chatbot model with RAG using DBRX\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/chatbot-rag/rag-basic-chain-1.png?raw=true\" style=\"float: right\" width=\"500px\">\n",
    "\n",
    "We've seen how Databricks makes it easy to ingest and prepare your documents, and deploy a Vector Search index on top of it with just clicks.\n",
    "\n",
    "Now that our Vector Searc index is ready, let's deploy a langchain application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ab9b965-6188-4312-8886-f33a73849c4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Configuring our Chain parameters\n",
    "\n",
    "As any appliaction, a RAG chain needs some configuration for each environement (ex: different catalog for test/prod environement). \n",
    "\n",
    "Databricks makes this easy with Chain Configurations. You can use this object to configure any value within your app, including the different system prompts and make it easy to test and deploy newer version with better prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d8d1f6e-6823-4e88-9705-00799fbb27b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "VECTOR_SEARCH_ENDPOINT_NAME=\"dhbb_vs_endpoint\"\n",
    "# For this first basic demo, we'll keep the configuration as a minimum. In real app, you can make all your RAG as a param (such as your prompt template to easily test different prompts!)\n",
    "chain_config = {\n",
    "    \"llm_model_serving_endpoint_name\": \"databricks-mixtral-8x7b-instruct\",  # the foundation model we want to use\n",
    "    \"vector_search_endpoint_name\": VECTOR_SEARCH_ENDPOINT_NAME,  # the endoint we want to use for vector search\n",
    "    \"vector_search_index\": f\"dhbb.bronze.dhbb_bronze_vs_index\",\n",
    "    \"llm_prompt_template\": \"\"\"Você é um assistente que responde perguntas sobre o acervo histório de pessoas políticas no Brasil. Use os seguintes verbetes como  contexto para responder à pergunta. Alguns pedaços de contexto podem ser irrelevantes, nesse caso você não deve usá-los para formar a resposta. Responda em português Brasil por padrão.\\n\\nContext: {context}\"\"\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "436b210c-25a5-454d-ace3-ed39a845a0f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Building our Langchain retriever\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/chatbot-rag/rag-basic-chain-2.png?raw=true\" style=\"float: right\" width=\"500px\">\n",
    "\n",
    "Let's start by building our Langchain retriever. \n",
    "\n",
    "It will be in charge of:\n",
    "\n",
    "* Creating the input question (our Managed Vector Search Index will compute the embeddings for us)\n",
    "* Calling the vector search index to find similar documents to augment the prompt with \n",
    "\n",
    "Databricks Langchain wrapper makes it easy to do in one step, handling all the underlying logic and API call for you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20db9e42-21b6-4f91-9f25-76045404f90c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import pandas_udf\n",
    "import pandas as pd\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col, udf, length, pandas_udf\n",
    "import os\n",
    "import mlflow\n",
    "import yaml\n",
    "from typing import Iterator\n",
    "from mlflow import MlflowClient\n",
    "mlflow.set_registry_uri('databricks-uc')\n",
    "\n",
    "# Workaround for a bug fix that is in progress\n",
    "mlflow.spark.autolog(disable=True)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Disable MLflow warnings\n",
    "import logging\n",
    "logging.getLogger('mlflow').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9eacaa8-55ef-4f02-846b-dc04b64b5608",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def display_txt_as_html(txt):\n",
    "    txt = txt.replace('\\n', '<br/>')\n",
    "    displayHTML(f'<div style=\"max-height: 150px\">{txt}</div>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf3e1b1c-21f0-40a4-a009-e6ed26739751",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True to VectorSearchClient().\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div style=\"max-height: 150px\">Passage: ---<br/>title: SIQUEIRA, Darci<br/>natureza: biográfico<br/>sexo: m<br/>cargos: <br/> - militar<br/> - dir. DASP 1974-1979<br/>---<br/><br/>«Darci Duarte de Siqueira» nasceu no Rio de Janeiro, então Distrito<br/>Federal, no dia 7 de janeiro de 1925, filho de Joaquim Rodrigues Alves<br/>de Siqueira e Jovina Duarte de Siqueira.<br/><br/>Sentou praça em março de 1942, ingressando no ano seguinte na Escola<br/>Militar de Resende, de onde saiu aspirante em 1946. Promovido a<br/>segundo-tenente em junho de 1947 e a primeiro-tenente em junho de 1949,<br/>chegou a capitão em abril de 1952.<br/><br/>Psicólogo, foi chefe da seção de psicotécnica da Academia Militar das<br/>Agulhas Negras (AMAN) de 1958 a 1964. Em 1965 foi transferido para a<br/>reserva e assumiu a chefia da divisão de recrutamento e seleção da<br/>Petrobras. Em 1967 tornou-se chefe do serviço de pessoal da mesma<br/>empresa, cargo que desempenhou até 1974, quando foi nomeado pelo<br/>presidente Ernesto Geisel (1974-1979) diretor-geral do Departamento<br/>Administrativo do Serviço Público (DASP), sucedendo a Glauco Lessa de<br/>Abreu e Silva. Durante sua gestão no DASP concedeu uma entrevista à<br/>revista «Veja», em agosto de 1976, na qual atribuiu a origem da mordomia<br/>nos cargos públicos, em Brasília, à falta de infra-estrutura daquela<br/>cidade à época da transferência da capital, implicando a existência de<br/>um salário indireto aos servidores do Estado para lá transferidos.<br/>Segundo ele, perdeu-se o controle sobre esta folha de pagamentos, que<br/>não se justificava mais em face do desenvolvimento da capital.<br/><br/>Em abril de 1979, com o fim do governo Geisel - substituído na<br/>presidência da República pelo general João Batista Figueiredo<br/>(1979-1985) -, Siqueira retornou ao seu antigo cargo na Petrobras, tendo<br/>sido sucedido no DASP por José Carlos Freire. Este segundo período de<br/>trabalho na estatal durou 11 anos. Em março de 1990, com a posse de<br/>Fernando Collor de Melo (1990-1992) na presidência da República, deixou<br/>a empresa, abandonando desde então a vida pública.<br/><br/>Faleceu na cidade do Rio de Janeiro, em 5 de abril de 1999.<br/><br/>Era casado com Regina Coelho de Sousa de Siqueira, com quem teve três<br/>filhos.<br/><br/><br/>Passage: ---<br/>title: SIQUEIRA, Jair<br/>natureza: biográfico<br/>sexo: m<br/>cargos: <br/> - dep. fed. MG 1995-1996<br/>---<br/><br/>«Jair Siqueira» nasceu em Paulistas (MG) no dia 30 de junho de 1936,<br/>filho de José Cândido Siqueira e de Emília Soares Ferreira.<br/><br/>Depois de fazer os primeiros estudos em sua cidade natal, transferiu-se<br/>para São Paulo, onde, em 1960, tornou-se funcionário da Gessy Lever e, a<br/>partir de 1967, gerente do Laboratório Andrômaco. Em 1971, iniciou o<br/>curso de direito na Universidade de São Paulo (USP), que concluiria em<br/>1975. Em 1973, tornou-se diretor da Indústria de Fitas Jomak. Em 1976<br/>fundou e assumiu a presidência da empresa Sigra, também em São Paulo. Em<br/>1984, fundou o jornal «Sul Gerais» em Pouso Alegre (MG), para onde se<br/>transferiu, quando abriu uma filial da companhia.<br/><br/>Em 1985, foi fundador e presidente do Centro das Indústrias do Médio<br/>Sapucaí e, no ano seguinte, tornou-se professor de teoria geral do<br/>estado na Faculdade de Direito do Sul de Minas, em Pouso Alegre. Em<br/>1987, participou do seminário Brasil-França sobre privatização de<br/>empresas públicas, realizado em Paris, e, no ano seguinte, filiou-se ao<br/>Partido da Frente Liberal (PFL) na cidade mineira.<br/><br/>Eleito prefeito de Pouso Alegre em outubro de 1988, não deixou suas<br/>atividades empresariais. Em 1989 tornou-se secretário da Fundação Sul<br/>Mineira de Ensino, administradora da Faculdade de Direito do Sul de<br/>Minas e, em 1991, foi fundador e diretor da empresa J. S. Têxtil<br/>Aviamentos e Tecidos. Deixou a prefeitura no final de seu mandato, no<br/>início de 1993.<br/><br/>Em outubro de 1994, obteve uma cadeira na Câmara dos Deputados por Minas<br/>Gerais, com a maioria dos votos provenientes de sua base eleitoral no<br/>sul do estado. Participou dos trabalhos legislativos como membro titular<br/>da Comissão de Constituição e Justiça. Em 1995, trocou o PFL pelo<br/>Partido Progressista Brasileiro (PPB).<br/><br/>Nas votações das emendas constitucionais propostas pelo governo Fernando<br/>Henrique Cardoso em 1995, pronunciou-se a favor da mudança no conceito<br/>de empresa nacional e da quebra dos monopólios estatal das<br/>telecomunicações, dos estados na distribuição de gás canalizado, das<br/>embarcações nacionais na navegação de cabotagem e da Petrobras na<br/>exploração de petróleo. Votou, apenas no primeiro turno, a favor da<br/>prorrogação do Fundo Social de Emergência (FSE), cujo nome foi<br/>modificado para Fundo de Estabilização Fiscal (FEF). Jair Siqueira não<br/>compareceu à votação em segundo turno.<br/><br/>No ano legislativo de 1996, esteve ausente na votação do projeto, afinal<br/>aprovado, de emenda constitucional do senador Antônio Carlos Valadares,<br/>filiado ao Partido Socialista Brasileiro (PSB), que instituiu a<br/>Contribuição Provisória sobre Movimentação Financeira (CPMF), criada<br/>para dotar o Ministério da Saúde de uma fonte suplementar de recursos.<br/><br/>Em outubro de 1996, elegeu-se pela segunda vez prefeito de Pouso Alegre,<br/>desta vez na legenda do PPB. Foi substituído na Câmara por Vagner do<br/>Nascimento. Assumiu a Prefeitura em janeiro de 1997. No pleito de 2000<br/>candidatou-se à reeleição desta vez no Partido Progressista (PP), mas<br/>não foi bem sucedido. Em 2004 disputou novamente a prefeitura de Pouso<br/>Alegre, agora na legenda do Partido Liberal (PL) e mais uma vez foi<br/>eleito. Foi empossado em janeiro de 2005 e em 2007 foi investigado e<br/>teve o mandato cassado por uma comissão parlamentar de inquérito (CPI)<br/>que funcionou na Câmara de Vereadores de Pouso Alegre. Foi acusado por<br/>seu ex-assessor Aerson Medeiros de fraude no decreto de estado de<br/>emergência e favoritismo a empresa Viasolo Engenharia Ambiental S.A.,<br/>responsável pela coleta de lixo no ano de 2005. Em abril de 2008 o<br/>Tribunal de Justiça de Minas Gerais anulou a cassação considerando que<br/>houvera irregularidades nos trabalhos da CPI, entre as quais falta de<br/>quorum por ocasião do recebimento da denúncia. Em outubro, candidatou-se<br/>mais uma vez a prefeitura de Pouso Alegre, mas não foi reeleito.<br/><br/>Membro do conselho fiscal da Fundação de Ensino Superior do Vale do<br/>Sapucaí e diretor do Movimento Social de Promoção Humana, casou-se com<br/>Lilian Narbot Siqueira, com quem teve três filhas.<br/><br/><br/><br/>Passage: ---<br/>title: SIQUEIRA, Belmiro<br/>natureza: biográfico<br/>sexo: m<br/>cargos: <br/> - dir. DASP 1967-1969 <br/>---<br/><br/>«Belmiro Siqueira», técnico em administração do Ministério da Fazenda,<br/>foi diretor-geral do Departamento Administrativo do Serviço Público<br/>(DASP) durante o governo do presidente Artur da Costa e Silva<br/>(1967-1969). Sucessor de Luís Vicente Belfort de Ouro Preto, assumiu o<br/>cargo em março de 1967 e em abril de 1969 foi substituído por Glauco<br/>Lessa Abreu e Silva.<br/><br/>Belmiro Siqueira serviu também na Escola de Administração Fazendária e<br/>foi ainda professor da Escola de Serviço Público do Rio de Janeiro e<br/>assessor da Federação de Associações Médicas.<br/><br/>Em 1976 criticou o Plano de Classificação de Cargos elaborado pelo DASP,<br/>então sob a direção de Darci Duarte de Siqueira, que retrucou<br/>classificando de omissa a sua administração.<br/><br/>Lecionava na Faculdades Integradas Estácio de Sá quando faleceu na<br/>cidade do Rio de Janeiro, no dia 29 de novembro de 1986.<br/><br/>Era casado com Eby Siqueira, com quem teve quatro filhos, um dos quais<br/>Wagner Siqueira, foi vereador no Rio de Janeiro.<br/><br/><br/></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "\"tr-baed7f83ca494fc995c2baaad4d5e234\"",
      "text/plain": [
       "Trace(request_id=tr-baed7f83ca494fc995c2baaad4d5e234)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from databricks.vector_search.client import VectorSearchClient\n",
    "from databricks_langchain.vectorstores import DatabricksVectorSearch\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "## Enable MLflow Tracing\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "## Load the chain's configuration\n",
    "model_config = mlflow.models.ModelConfig(development_config=chain_config)\n",
    "\n",
    "## Turn the Vector Search index into a LangChain retriever\n",
    "vector_search_as_retriever = DatabricksVectorSearch(\n",
    "    endpoint=model_config.get(\"vector_search_endpoint_name\"),\n",
    "    index_name=model_config.get(\"vector_search_index\"),\n",
    "    columns=[\"file_name\", \"content\"],\n",
    ").as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# Method to format the docs returned by the retriever into the prompt (keep only the text from chunks)\n",
    "def format_context(docs):\n",
    "    chunk_contents = [f\"Passage: {d.page_content}\\n\" for d in docs]\n",
    "    return \"\".join(chunk_contents)\n",
    "\n",
    "#Let's try our retriever chain:\n",
    "relevant_docs = (vector_search_as_retriever | RunnableLambda(format_context)| StrOutputParser()).invoke('Quem foi José Siqueira?')\n",
    "\n",
    "display_txt_as_html(relevant_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75433893-c7f6-408b-8319-b1a05313198e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "You can see in the results that Databricks automatically trace your chain details and you can debug each steps and review the documents retrieved.\n",
    "\n",
    "## Building Databricks Chat Model to query our demo's Foundational LLM\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/chatbot-rag/rag-basic-chain-3.png?raw=true\" style=\"float: right\" width=\"500px\">\n",
    "\n",
    "Our chatbot will be using Meta's Llama open source model. However, it could be utilized with DBRX (_pictured_), or any other LLMs served on Databricks.  \n",
    "\n",
    "Other types of models that could be utilized include:\n",
    "\n",
    "- Databricks Foundation models (_what we will use by default in this demo_)\n",
    "- Your organization's custom, fine-tuned model\n",
    "- An external model provider (_such as Azure OpenAI_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea62d95c-5214-40ab-9fac-b29612906c71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div style=\"max-height: 150px\"> José Siqueira foi um jornalista, escritor e político brasileiro, nascido em 1883 e falecido em 1960. Ele foi um dos fundadores do Partido Comunista do Brasil (PCB) em 1922 e atuou como seu secretário-geral entre 1932 e 1943. Além disso, Siqueira foi um dos principais líderes do movimento operário no Brasil durante as primeiras décadas do século XX.<br/><br/>Em sua carreira jornalística, Siqueira fundou e dirigiu diversos periódicos, como \"A Classe Operária\" e \"O Sindicalista\", que se tornaram importantes veículos de comunicação e organização para o movimento trabalhista. Ele também escreveu vários livros sobre temas políticos e sociais, como \"O Marxismo e a Questão Agrária\" e \"A Crise do Capitalismo\".<br/><br/>No entanto, é importante notar que as informações sobre José Siqueira podem ser controversas, uma vez que ele foi um ativo militante comunista em um período em que o comunismo era uma ideologia perseguida no Brasil. Algumas fontes podem oferecer uma visão mais crítica ou negativa de sua vida e obra.</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "\"tr-1a158b12385448db92e4b5d8a27e8a99\"",
      "text/plain": [
       "Trace(request_id=tr-1a158b12385448db92e4b5d8a27e8a99)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from databricks_langchain.chat_models import ChatDatabricks\n",
    "from operator import itemgetter\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [  \n",
    "        (\"system\", model_config.get(\"llm_prompt_template\")), # Contains the instructions from the configuration\n",
    "        (\"user\", \"{question}\") #user's questions\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Our foundation model answering the final prompt\n",
    "model = ChatDatabricks(\n",
    "    endpoint=model_config.get(\"llm_model_serving_endpoint_name\"),\n",
    "    extra_params={\"temperature\": 0.01, \"max_tokens\": 1500}\n",
    ")\n",
    "\n",
    "#Let's try our prompt:\n",
    "answer = (prompt | model | StrOutputParser()).invoke({'question':'Quem foi José Siqueira?', 'context': ''})\n",
    "display_txt_as_html(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de1eb44c-69ca-4cc6-8cfe-43e7afdea2db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Putting it together in a final chain, supporting the standard Chat Completion format\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/chatbot-rag/rag-basic-chain-4.png?raw=true\" style=\"float: right\" width=\"500px\">\n",
    "\n",
    "\n",
    "Let's now merge the retriever and the model in a single Langchain chain.\n",
    "\n",
    "We will use a custom langchain template for our assistant to give proper answer.\n",
    "\n",
    "We will make sure our chain support the standard Chat Completion API input schema : `{\"messages\": [{\"role\": \"user\", \"content\": \"What is Retrieval-augmented Generation?\"}]}`\n",
    "\n",
    "Make sure you take some time to try different templates and adjust your assistant tone and personality for your requirement.\n",
    "\n",
    "*Note that we won't support history in this first version, and will only take the last message as the question. See the advanced demo for a more complete example.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47edb8de-80a1-47dc-adce-606f0e137fdc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Return the string contents of the most recent messages: [{...}] from the user to be used as input question\n",
    "def extract_user_query_string(chat_messages_array):\n",
    "    return chat_messages_array[-1][\"content\"]\n",
    "\n",
    "# RAG Chain\n",
    "chain = (\n",
    "    {\n",
    "        \"question\": itemgetter(\"messages\") | RunnableLambda(extract_user_query_string),\n",
    "        \"context\": itemgetter(\"messages\")\n",
    "        | RunnableLambda(extract_user_query_string)\n",
    "        | vector_search_as_retriever\n",
    "        | RunnableLambda(format_context),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0fe36225-4572-40c8-9891-88dfe3d064b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "#### Databricks will track all the chain for you\n",
    "\n",
    "<img src=\"https://ai-cookbook.io/_images/mlflow_trace2.gif\" width=\"600px\" style=\"float: right; margin-left: 10px\">\n",
    "\n",
    "As you can see in the cell result below, Databricks automatically trace the chain call. \n",
    "\n",
    "This makes it super easy to debug and improve your chain!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e96c81f-89ec-49c3-94a4-3d5e8df3c1c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Francisco Everardo Oliveira Silva\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "\"tr-1fb9506d918e44318793aad15b848fc6\"",
      "text/plain": [
       "Trace(request_id=tr-1fb9506d918e44318793aad15b848fc6)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's give it a try:\n",
    "input_example = {\"messages\": [ {\"role\": \"user\", \"content\": \"Qual é o nome do Tiririca?\"}]}\n",
    "answer = chain.invoke(input_example)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe31b765-3545-4db9-80df-00f0a7722be8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Deploy a RAG Chain to a web-based UI for stakeholder feedback\n",
    "\n",
    "Our chain is now ready! \n",
    "\n",
    "Let's first register the Rag Chain model to MLFlow and Unity Catalog, and then use Agent Framework to deploy to the Agent Evaluation stakeholder review application which is backed by a scalable, production-ready Model Serving endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e161ff3-84a5-4487-9355-f58f35e6d479",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True to VectorSearchClient().\n[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True to VectorSearchClient().\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c97c77652b4e4d0eb2156e230c1769cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<head>\n",
       "  <link\n",
       "    rel=\"stylesheet\"\n",
       "    href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/xcode.min.css\"\n",
       "  />\n",
       "  <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js\"></script>\n",
       "  <script>\n",
       "    hljs.highlightAll();\n",
       "  </script>\n",
       "  <style>\n",
       "    body {\n",
       "      margin: 0;\n",
       "      font-family: -apple-system, BlinkMacSystemFont, Segoe UI, Roboto,\n",
       "        Helvetica Neue, Arial, Noto Sans, sans-serif, Apple Color Emoji,\n",
       "        Segoe UI Emoji, Segoe UI Symbol, Noto Color Emoji;\n",
       "      -webkit-tap-highlight-color: rgba(0, 0, 0, 0);\n",
       "      margin: 0;\n",
       "      font-weight: 400;\n",
       "      font-size: 13px;\n",
       "      line-height: 18px;\n",
       "      color: rgb(17, 23, 28);\n",
       "    }\n",
       "    code {\n",
       "      line-height: 18px;\n",
       "      font-size: 11px;\n",
       "      background: rgb(250, 250, 250) !important;\n",
       "    }\n",
       "    pre {\n",
       "      background: rgb(250, 250, 250);\n",
       "      margin: 0;\n",
       "      display: none;\n",
       "    }\n",
       "    pre.active {\n",
       "      display: unset;\n",
       "    }\n",
       "    button {\n",
       "      white-space: nowrap;\n",
       "      text-align: center;\n",
       "      position: relative;\n",
       "      cursor: pointer;\n",
       "      background: rgba(34, 114, 180, 0) !important;\n",
       "      color: rgb(34, 114, 180) !important;\n",
       "      border-color: rgba(34, 114, 180, 0) !important;\n",
       "      padding: 4px 6px !important;\n",
       "      text-decoration: none !important;\n",
       "      line-height: 20px !important;\n",
       "      box-shadow: none !important;\n",
       "      height: 32px !important;\n",
       "      display: inline-flex !important;\n",
       "      -webkit-box-align: center !important;\n",
       "      align-items: center !important;\n",
       "      -webkit-box-pack: center !important;\n",
       "      justify-content: center !important;\n",
       "      vertical-align: middle !important;\n",
       "    }\n",
       "    p {\n",
       "      margin: 0;\n",
       "      padding: 0;\n",
       "    }\n",
       "    button:hover {\n",
       "      background: rgba(34, 114, 180, 0.08) !important;\n",
       "      color: rgb(14, 83, 139) !important;\n",
       "    }\n",
       "    button:active {\n",
       "      background: rgba(34, 114, 180, 0.16) !important;\n",
       "      color: rgb(4, 53, 93) !important;\n",
       "    }\n",
       "    h1 {\n",
       "      margin-top: 4px;\n",
       "      font-size: 22px;\n",
       "    }\n",
       "    .info {\n",
       "      font-size: 12px;\n",
       "      font-weight: 500;\n",
       "      line-height: 16px;\n",
       "      color: rgb(95, 114, 129);\n",
       "    }\n",
       "    .tabs {\n",
       "      margin-top: 10px;\n",
       "      border-bottom: 1px solid rgb(209, 217, 225) !important;\n",
       "      display: flex;\n",
       "      line-height: 24px;\n",
       "    }\n",
       "    .tab {\n",
       "      font-size: 13px;\n",
       "      font-weight: 600 !important;\n",
       "      cursor: pointer;\n",
       "      margin: 0 24px 0 2px;\n",
       "      padding-left: 2px;\n",
       "    }\n",
       "    .tab:hover {\n",
       "      color: rgb(14, 83, 139) !important;\n",
       "    }\n",
       "    .tab.active {\n",
       "      border-bottom: 3px solid rgb(34, 114, 180) !important;\n",
       "    }\n",
       "    .link {\n",
       "      margin-left: 12px;\n",
       "      display: inline-block;\n",
       "      text-decoration: none;\n",
       "      color: rgb(34, 114, 180) !important;\n",
       "      font-size: 13px;\n",
       "      font-weight: 400;\n",
       "    }\n",
       "    .link:hover {\n",
       "      color: rgb(14, 83, 139) !important;\n",
       "    }\n",
       "    .link-content {\n",
       "      display: flex;\n",
       "      gap: 6px;\n",
       "      align-items: center;\n",
       "    }\n",
       "    .caret-up {\n",
       "      transform: rotate(180deg);\n",
       "    }\n",
       "  </style>\n",
       "</head>\n",
       "<body>\n",
       "  <div style=\"display: flex; align-items: center\">\n",
       "    The logged model is compatible with the Mosaic AI Agent Framework.\n",
       "    <button onclick=\"toggleCode()\">\n",
       "      See how to evaluate the model&nbsp;\n",
       "      <span\n",
       "        role=\"img\"\n",
       "        id=\"caret\"\n",
       "        aria-hidden=\"true\"\n",
       "        class=\"anticon css-6xix1i\"\n",
       "        style=\"font-size: 14px\"\n",
       "        ><svg\n",
       "          xmlns=\"http://www.w3.org/2000/svg\"\n",
       "          width=\"1em\"\n",
       "          height=\"1em\"\n",
       "          fill=\"none\"\n",
       "          viewBox=\"0 0 16 16\"\n",
       "          aria-hidden=\"true\"\n",
       "          focusable=\"false\"\n",
       "          class=\"\"\n",
       "        >\n",
       "          <path\n",
       "            fill=\"currentColor\"\n",
       "            fill-rule=\"evenodd\"\n",
       "            d=\"M8 8.917 10.947 6 12 7.042 8 11 4 7.042 5.053 6z\"\n",
       "            clip-rule=\"evenodd\"\n",
       "          ></path>\n",
       "        </svg>\n",
       "      </span>\n",
       "    </button>\n",
       "  </div>\n",
       "  <div id=\"code\" style=\"display: none\">\n",
       "    <h1>\n",
       "      Agent evaluation\n",
       "      <a\n",
       "        class=\"link\"\n",
       "        href=\"https://docs.databricks.com/en/generative-ai/agent-evaluation/synthesize-evaluation-set.html?utm_source=mlflow.log_model&utm_medium=notebook\"\n",
       "        target=\"_blank\"\n",
       "      >\n",
       "        <span class=\"link-content\">\n",
       "          Learn more\n",
       "          <span role=\"img\" aria-hidden=\"true\" class=\"anticon css-6xix1i\"\n",
       "            ><svg\n",
       "              xmlns=\"http://www.w3.org/2000/svg\"\n",
       "              width=\"1em\"\n",
       "              height=\"1em\"\n",
       "              fill=\"none\"\n",
       "              viewBox=\"0 0 16 16\"\n",
       "              aria-hidden=\"true\"\n",
       "              focusable=\"false\"\n",
       "              class=\"\"\n",
       "            >\n",
       "              <path\n",
       "                fill=\"currentColor\"\n",
       "                d=\"M10 1h5v5h-1.5V3.56L8.53 8.53 7.47 7.47l4.97-4.97H10z\"\n",
       "              ></path>\n",
       "              <path\n",
       "                fill=\"currentColor\"\n",
       "                d=\"M1 2.75A.75.75 0 0 1 1.75 2H8v1.5H2.5v10h10V8H14v6.25a.75.75 0 0 1-.75.75H1.75a.75.75 0 0 1-.75-.75z\"\n",
       "              ></path></svg></span></span\n",
       "      ></a>\n",
       "    </h1>\n",
       "    <p class=\"info\">\n",
       "      Copy the following code snippet in a notebook cell (right click → copy)\n",
       "    </p>\n",
       "    <div class=\"tabs\">\n",
       "      <div class=\"tab active\" onclick=\"tabClicked(0)\">Using synthetic data</div>\n",
       "      <div class=\"tab\" onclick=\"tabClicked(1)\">Using your own dataset</div>\n",
       "    </div>\n",
       "    <div style=\"height: 472px\">\n",
       "      <pre\n",
       "        class=\"active\"\n",
       "      ><code class=\"language-python\">%pip install -U databricks-agents\n",
       "dbutils.library.restartPython()\n",
       "## Run the above in a separate cell ##\n",
       "\n",
       "from databricks.agents.evals import generate_evals_df\n",
       "import mlflow\n",
       "\n",
       "agent_description = &#34;A chatbot that answers questions about Databricks.&#34;\n",
       "question_guidelines = &#34;&#34;&#34;\n",
       "# User personas\n",
       "- A developer new to the Databricks platform\n",
       "# Example questions\n",
       "- What API lets me parallelize operations over rows of a delta table?\n",
       "&#34;&#34;&#34;\n",
       "# TODO: Spark/Pandas DataFrame with &#34;content&#34; and &#34;doc_uri&#34; columns.\n",
       "docs = spark.table(&#34;catalog.schema.my_table_of_docs&#34;)\n",
       "evals = generate_evals_df(\n",
       "    docs=docs,\n",
       "    num_evals=25,\n",
       "    agent_description=agent_description,\n",
       "    question_guidelines=question_guidelines,\n",
       ")\n",
       "eval_result = mlflow.evaluate(data=evals, model=&#34;runs:/8d2d7eb279de484aa5a7ffb4b68b2d55/chain&#34;, model_type=&#34;databricks-agent&#34;)</code></pre>\n",
       "\n",
       "      <pre><code class=\"language-python\">%pip install -U databricks-agents\n",
       "dbutils.library.restartPython()\n",
       "## Run the above in a separate cell ##\n",
       "\n",
       "import pandas as pd\n",
       "import mlflow\n",
       "\n",
       "evals = [\n",
       "    {\n",
       "        &#34;request&#34;: {\n",
       "            &#34;messages&#34;: [\n",
       "                {&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;How do I convert a Spark DataFrame to Pandas?&#34;}\n",
       "            ],\n",
       "        },\n",
       "        # Optional, needed for judging correctness.\n",
       "        &#34;expected_facts&#34;: [\n",
       "            &#34;To convert a Spark DataFrame to Pandas, you can use the toPandas() method.&#34;\n",
       "        ],\n",
       "    }\n",
       "]\n",
       "eval_result = mlflow.evaluate(\n",
       "    data=pd.DataFrame.from_records(evals), model=&#34;runs:/8d2d7eb279de484aa5a7ffb4b68b2d55/chain&#34;, model_type=&#34;databricks-agent&#34;\n",
       ")</code></pre>\n",
       "    </div>\n",
       "  </div>\n",
       "  <script>\n",
       "    var codeShown = false;\n",
       "    function clip(el) {\n",
       "      var range = document.createRange();\n",
       "      range.selectNodeContents(el);\n",
       "      var sel = window.getSelection();\n",
       "      sel.removeAllRanges();\n",
       "      sel.addRange(range);\n",
       "    }\n",
       "\n",
       "    function toggleCode() {\n",
       "      if (codeShown) {\n",
       "        document.getElementById(\"code\").style.display = \"none\";\n",
       "        codeShown = false;\n",
       "      } else {\n",
       "        document.getElementById(\"code\").style.display = \"block\";\n",
       "        clip(document.querySelector(\"pre.active\"));\n",
       "        codeShown = true;\n",
       "      }\n",
       "      document.getElementById(\"caret\").classList.toggle(\"caret-up\");\n",
       "    }\n",
       "\n",
       "    function tabClicked(tabIndex) {\n",
       "      document.querySelectorAll(\".tab\").forEach((tab, index) => {\n",
       "        if (index === tabIndex) {\n",
       "          tab.classList.add(\"active\");\n",
       "        } else {\n",
       "          tab.classList.remove(\"active\");\n",
       "        }\n",
       "      });\n",
       "      document.querySelectorAll(\"pre\").forEach((pre, index) => {\n",
       "        if (index === tabIndex) {\n",
       "          pre.classList.add(\"active\");\n",
       "        } else {\n",
       "          pre.classList.remove(\"active\");\n",
       "        }\n",
       "      });\n",
       "      clip(document.querySelector(\"pre.active\"));\n",
       "    }\n",
       "  </script>\n",
       "</body>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'dhbb.bronze.dhbb_rag_mixtral'.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b64737dace54a96990282616108e51d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8407532c1bee4b6fac02e1cc7fc4d2de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'dhbb.bronze.dhbb_rag_mixtral'.\n"
     ]
    }
   ],
   "source": [
    "from mlflow.models.resources import DatabricksVectorSearchIndex, DatabricksServingEndpoint\n",
    "# Log the model to MLflow\n",
    "with mlflow.start_run(run_name=\"dhbb_rag_bot_mixtral\"):\n",
    "  logged_chain_info = mlflow.langchain.log_model(\n",
    "          #Note: In classical ML, MLflow works by serializing the model object.  In generative AI, chains often include Python packages that do not serialize.  Here, we use MLflow's new code-based logging, where we saved our chain under the chain notebook and will use this code instead of trying to serialize the object.\n",
    "          lc_model=os.path.join(os.getcwd(), 'chain'),  # Chain code file e.g., /path/to/the/chain.py \n",
    "          model_config=chain_config, # Chain configuration \n",
    "          artifact_path=\"chain\", # Required by MLflow, the chain's code/config are saved in this directory\n",
    "          input_example=input_example,\n",
    "          example_no_conversion=True,  # Required by MLflow to use the input_example as the chain's schema,\n",
    "          # Specify resources for automatic authentication passthrough\n",
    "          resources=[\n",
    "            DatabricksVectorSearchIndex(index_name=model_config.get(\"vector_search_index\")),\n",
    "            DatabricksServingEndpoint(endpoint_name=model_config.get(\"llm_model_serving_endpoint_name\"))\n",
    "          ]\n",
    "      )\n",
    "\n",
    "MODEL_NAME = \"dhbb_rag_mixtral\"\n",
    "MODEL_NAME_FQN = f\"dhbb.bronze.{MODEL_NAME}\"\n",
    "# Register to UC\n",
    "uc_registered_model_info = mlflow.register_model(model_uri=logged_chain_info.model_uri, name=MODEL_NAME_FQN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6328f455-81d5-480b-a879-6a97da08509f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's now deploy the Mosaic AI **Agent Evaluation review application** using the model we just created!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79cee61e-bd8a-4acf-a30f-ea930950e396",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def wait_for_model_serving_endpoint_to_be_ready(ep_name):\n",
    "    from databricks.sdk import WorkspaceClient\n",
    "    from databricks.sdk.service.serving import EndpointStateReady, EndpointStateConfigUpdate\n",
    "    import time\n",
    "\n",
    "    # TODO make the endpoint name as a param\n",
    "    # Wait for it to be ready\n",
    "    w = WorkspaceClient()\n",
    "    state = \"\"\n",
    "    for i in range(200):\n",
    "        state = w.serving_endpoints.get(ep_name).state\n",
    "        if state.config_update == EndpointStateConfigUpdate.IN_PROGRESS:\n",
    "            if i % 40 == 0:\n",
    "                print(f\"Waiting for endpoint to deploy {ep_name}. Current state: {state}\")\n",
    "            time.sleep(10)\n",
    "        elif state.ready == EndpointStateReady.READY:\n",
    "          print('endpoint ready.')\n",
    "          return\n",
    "        else:\n",
    "          break\n",
    "    raise Exception(f\"Couldn't start the endpoint, timeout, please check your endpoint for more details: {state}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f76d6efb-6128-4390-ae1c-e6d9588c1d3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-10056e90-3e3e-40b1-bb51-27e798730857/lib/python3.10/site-packages/mlflow/pyfunc/utils/data_validation.py:166: UserWarning: \u001B[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001B[0m\n  color_warning(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81457d52f9ab445692575221e6074d1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:databricks.agents.utils.mlflow_utils:Agent model version did not have any of the recommended agent signatures. Falling back to checking agent model version compatibility with legacy signatures. Databricks recommends updating and re-logging agents to use the latest signatures; legacy signatures will be removed in the next major MLflow release. See https://docs.databricks.com/en/generative-ai/agent-framework/agent-schema.html for additional details\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5634945c3d83462caff4c59939ce9103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n    Deployment of dhbb.bronze.dhbb_rag_mixtral version 1 initiated.  This can take up to 15 minutes and the Review App & Query Endpoint will not work until this deployment finishes.\n\n    View status: https://fgv-pocs-genie.cloud.databricks.com/ml/endpoints/agents_dhbb-bronze-dhbb_rag_mixtral\n    Review App: https://fgv-pocs-genie.cloud.databricks.com/ml/review/dhbb.bronze.dhbb_rag_mixtral/1?o=4008450564360146\n    Monitoring guide: https://docs.databricks.com/en/generative-ai/agent-evaluation/evaluating-production-traffic.html?utm_source=agents.deploy&utm_medium=python-sdk\n    \nWaiting for endpoint to deploy agents_dhbb-bronze-dhbb_rag_mixtral. Current state: EndpointState(config_update=<EndpointStateConfigUpdate.IN_PROGRESS: 'IN_PROGRESS'>, ready=<EndpointStateReady.NOT_READY: 'NOT_READY'>)\nWaiting for endpoint to deploy agents_dhbb-bronze-dhbb_rag_mixtral. Current state: EndpointState(config_update=<EndpointStateConfigUpdate.IN_PROGRESS: 'IN_PROGRESS'>, ready=<EndpointStateReady.NOT_READY: 'NOT_READY'>)\nendpoint ready.\n"
     ]
    }
   ],
   "source": [
    "from databricks import agents\n",
    "# Deploy to enable the Review APP and create an API endpoint\n",
    "# Note: scaling down to zero will provide unexpected behavior for the chat app. Set it to false for a prod-ready application.\n",
    "deployment_info = agents.deploy(MODEL_NAME_FQN, model_version=uc_registered_model_info.version, scale_to_zero=True)\n",
    "\n",
    "instructions_to_reviewer = f\"\"\"## Instruções para testar o chat bot para fazer perguntas aos verbetes disponíveis no DHBB via Mixtral 8x7b\n",
    "\n",
    "Suas contribuições são inestimáveis ​​para a equipe de desenvolvimento do hackathon ChatFGV. Ao fornecer feedback e correções detalhadas, você nos ajuda a corrigir problemas e melhorar a qualidade geral do aplicativo. Contamos com sua experiência para identificar quaisquer lacunas ou áreas que precisem de aprimoramento.\"\"\"\n",
    "\n",
    "# Add the user-facing instructions to the Review App\n",
    "agents.set_review_instructions(MODEL_NAME_FQN, instructions_to_reviewer)\n",
    "\n",
    "wait_for_model_serving_endpoint_to_be_ready(deployment_info.endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51ce663d-4e5c-4aa9-985f-24bb7cd715db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Use the Mosaic AI Agent Evaluation to evaluate your RAG applications\n",
    "\n",
    "## Chat with your bot and build your validation dataset!\n",
    "\n",
    "Our Chat Bot is now live. Databricks provides a built-in chatbot application that you can use to test the chatbot and give feedbacks on its answer.\n",
    "\n",
    "You can easily give access to external domain experts and have them test and review the bot.  **Your domain experts do NOT need to have Databricks Workspace access** - you can assign permissions to any user in your SSO if you have enabled [SCIM](https://docs.databricks.com/en/admin/users-groups/scim/index.html)\n",
    "\n",
    "This is a critical step to build or improve your evaluation dataset: have users ask questions to your bot, and provide the bot with output answer when they don't answer properly.\n",
    "\n",
    "Your Chatbot is automatically capturing all stakeholder questions and bot responses, including an MLflow trace for each, into Delta Tables in your Lakehouse. On top of that, Databricks makes it easy to track feedback from your end user: if the chatbot doesn't give a good answer and the user gives a thumbdown, their feedback is included in the Delta Tables.\n",
    "\n",
    "Once your eval dataset is ready, you'll then be able to leverage it for offline evaluation to measure your new chatbot performance, and also potentially to Fine Tune your model.\n",
    "<br/>\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/chatbot-rag/eval-framework.gif?raw=true\" width=\"1000px\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2c266aa-b7a2-48ef-8b77-d77e83089d9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\nReview App URL to share with your stakeholders: https://fgv-pocs-genie.cloud.databricks.com/ml/review/dhbb.bronze.dhbb_rag_mixtral/1?o=4008450564360146\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n\\nReview App URL to share with your stakeholders: {deployment_info.review_app_url}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5212472769178870,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "RAG-DHBB-mixtral-8x7b-instruct",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}